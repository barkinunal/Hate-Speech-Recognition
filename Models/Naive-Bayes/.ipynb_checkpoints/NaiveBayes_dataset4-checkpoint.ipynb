{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "6BzfmTa4ZMBX",
    "outputId": "948ab020-77e1-4db7-f74f-d98495801089"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "70pBbdzXaqyT"
   },
   "outputs": [],
   "source": [
    "__author__ = \"Barkın Ünal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ImT10IYlZmNY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "\n",
    "def classification_report_with_accuracy_score(y_true, y_pred):\n",
    "\n",
    "    print(classification_report(y_true, y_pred)) # print classification report\n",
    "    return accuracy_score(y_true, y_pred) # return accuracy score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "v7BT1MnCZzro",
    "outputId": "075b50d3-1d4a-4ea9-e2d1-d2d836290c4e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Horse face hoe stop playing before I show the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alex Brosas another idiot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>as Nancy Reagan would say   just say FUCKING ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not being homophobic here     but uhhhhhhhhhh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I hate er chase because if the Bitch that work...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29693</th>\n",
       "      <td>I stopped fucking with people who never fell t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29694</th>\n",
       "      <td>She must of made a ugly bitch mad af  Tried t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29695</th>\n",
       "      <td>this fucked up bruh</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29696</th>\n",
       "      <td>Oasis  cover of The Who   My Generation is fu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29697</th>\n",
       "      <td>ion wish a heartbreak on anybody    not even ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29698 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text label\n",
       "0       Horse face hoe stop playing before I show the...     1\n",
       "1                             Alex Brosas another idiot      1\n",
       "2       as Nancy Reagan would say   just say FUCKING ...     1\n",
       "3       Not being homophobic here     but uhhhhhhhhhh...     1\n",
       "4      I hate er chase because if the Bitch that work...     0\n",
       "...                                                  ...   ...\n",
       "29693  I stopped fucking with people who never fell t...     0\n",
       "29694   She must of made a ugly bitch mad af  Tried t...     0\n",
       "29695                               this fucked up bruh      0\n",
       "29696   Oasis  cover of The Who   My Generation is fu...     0\n",
       "29697   ion wish a heartbreak on anybody    not even ...     0\n",
       "\n",
       "[29698 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/content/drive/My Drive/ML_Term_Project/\"\n",
    "data = pd.read_csv(path + \"dataset_4.csv\", index_col = 0)\n",
    "data = data.rename({\"0\": \"text\"}, axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qrDZiZbFaB-b"
   },
   "outputs": [],
   "source": [
    "def bag_word(documents, stop_word=True, n_gram=(1,1)):\n",
    "\n",
    "    # If stop words want to be excluded.\n",
    "    if stop_word:\n",
    "        if n_gram == (1,1):\n",
    "            tfidfconverter = TfidfVectorizer(ngram_range=n_gram, stop_words='english')\n",
    "        else:\n",
    "            tfidfconverter = TfidfVectorizer(ngram_range=n_gram, min_df=0.0005, stop_words='english')\n",
    "    \n",
    "    # If stop words want to be included\n",
    "    if not stop_word:\n",
    "        if n_gram == (1, 1):\n",
    "            tfidfconverter = TfidfVectorizer(ngram_range=n_gram)\n",
    "        else:\n",
    "            tfidfconverter = TfidfVectorizer(ngram_range=n_gram, min_df=0.0005)\n",
    "\n",
    "    X = tfidfconverter.fit_transform(documents).toarray()\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udkoW-VEa19R"
   },
   "outputs": [],
   "source": [
    "def get_accuracy(prediction, y_test):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(len(prediction)):\n",
    "        if prediction[i] == y_test.iloc[i]:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zI89cDtMa4Ve"
   },
   "outputs": [],
   "source": [
    "def draw_plot(range_list, value_list, title_str, x_label_str, y_label_str):\n",
    "\n",
    "    plt.plot(range_list, value_list, color=\"b\", linestyle=\"dashed\", marker=\"o\", markerfacecolor=\"r\")\n",
    "    plt.title(title_str)\n",
    "    plt.xlabel(x_label_str)\n",
    "    plt.ylabel(y_label_str)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "L4VY7K5Ta5xk",
    "outputId": "49410265-b27d-4fef-df49-b9892138ee0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.60      0.61      1549\n",
      "           1       0.47      0.67      0.55      1028\n",
      "        spam       0.00      0.00      0.00       393\n",
      "\n",
      "    accuracy                           0.54      2970\n",
      "   macro avg       0.36      0.42      0.39      2970\n",
      "weighted avg       0.49      0.54      0.51      2970\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.58      0.60      1550\n",
      "           1       0.47      0.70      0.56      1027\n",
      "        spam       0.50      0.00      0.01       393\n",
      "\n",
      "    accuracy                           0.55      2970\n",
      "   macro avg       0.53      0.43      0.39      2970\n",
      "weighted avg       0.56      0.55      0.51      2970\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.84      0.74      1550\n",
      "           1       0.69      0.67      0.68      1027\n",
      "        spam       0.50      0.00      0.01       393\n",
      "\n",
      "    accuracy                           0.67      2970\n",
      "   macro avg       0.62      0.51      0.48      2970\n",
      "weighted avg       0.65      0.67      0.62      2970\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.85      0.74      1550\n",
      "           1       0.70      0.68      0.69      1027\n",
      "        spam       0.00      0.00      0.00       393\n",
      "\n",
      "    accuracy                           0.68      2970\n",
      "   macro avg       0.45      0.51      0.48      2970\n",
      "weighted avg       0.59      0.68      0.63      2970\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.85      0.75      1550\n",
      "           1       0.70      0.68      0.69      1027\n",
      "        spam       0.00      0.00      0.00       393\n",
      "\n",
      "    accuracy                           0.68      2970\n",
      "   macro avg       0.46      0.51      0.48      2970\n",
      "weighted avg       0.59      0.68      0.63      2970\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.85      0.74      1550\n",
      "           1       0.70      0.66      0.68      1027\n",
      "        spam       0.67      0.01      0.01       393\n",
      "\n",
      "    accuracy                           0.67      2970\n",
      "   macro avg       0.67      0.51      0.48      2970\n",
      "weighted avg       0.67      0.67      0.62      2970\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.84      0.74      1550\n",
      "           1       0.68      0.66      0.67      1027\n",
      "        spam       0.00      0.00      0.00       393\n",
      "\n",
      "    accuracy                           0.67      2970\n",
      "   macro avg       0.45      0.50      0.47      2970\n",
      "weighted avg       0.58      0.67      0.62      2970\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.94      0.73      1550\n",
      "           1       0.81      0.41      0.55      1027\n",
      "        spam       0.00      0.00      0.00       393\n",
      "\n",
      "    accuracy                           0.64      2970\n",
      "   macro avg       0.47      0.45      0.43      2970\n",
      "weighted avg       0.59      0.64      0.57      2970\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      1.00      0.71      1550\n",
      "           1       1.00      0.14      0.24      1027\n",
      "        spam       0.00      0.00      0.00       392\n",
      "\n",
      "    accuracy                           0.57      2969\n",
      "   macro avg       0.52      0.38      0.32      2969\n",
      "weighted avg       0.63      0.57      0.45      2969\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      1.00      0.69      1549\n",
      "           1       0.87      0.06      0.12      1027\n",
      "        spam       0.00      0.00      0.00       393\n",
      "\n",
      "    accuracy                           0.54      2969\n",
      "   macro avg       0.47      0.35      0.27      2969\n",
      "weighted avg       0.58      0.54      0.40      2969\n",
      "\n",
      "MultinomialNB  1 - gram without stopwords :  0.6205761102662416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.55      0.60      1549\n",
      "           1       0.46      0.74      0.57      1028\n",
      "        spam       0.00      0.00      0.00       393\n",
      "\n",
      "    accuracy                           0.55      2970\n",
      "   macro avg       0.37      0.43      0.39      2970\n",
      "weighted avg       0.50      0.55      0.51      2970\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.51      0.58      1550\n",
      "           1       0.46      0.80      0.59      1027\n",
      "        spam       0.33      0.00      0.01       393\n",
      "\n",
      "    accuracy                           0.54      2970\n",
      "   macro avg       0.49      0.44      0.39      2970\n",
      "weighted avg       0.55      0.54      0.51      2970\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.75      0.72      1550\n",
      "           1       0.62      0.79      0.69      1027\n",
      "        spam       0.00      0.00      0.00       393\n",
      "\n",
      "    accuracy                           0.66      2970\n",
      "   macro avg       0.44      0.51      0.47      2970\n",
      "weighted avg       0.58      0.66      0.62      2970\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.77      0.73      1550\n",
      "           1       0.63      0.77      0.69      1027\n",
      "        spam       0.00      0.00      0.00       393\n",
      "\n",
      "    accuracy                           0.66      2970\n",
      "   macro avg       0.44      0.51      0.47      2970\n",
      "weighted avg       0.58      0.66      0.62      2970\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.77      0.72      1550\n",
      "           1       0.63      0.76      0.69      1027\n",
      "        spam       0.00      0.00      0.00       393\n",
      "\n",
      "    accuracy                           0.66      2970\n",
      "   macro avg       0.44      0.51      0.47      2970\n",
      "weighted avg       0.58      0.66      0.62      2970\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.76      0.73      1550\n",
      "           1       0.64      0.79      0.70      1027\n",
      "        spam       0.00      0.00      0.00       393\n",
      "\n",
      "    accuracy                           0.67      2970\n",
      "   macro avg       0.44      0.52      0.48      2970\n",
      "weighted avg       0.58      0.67      0.62      2970\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.77      0.73      1550\n",
      "           1       0.63      0.77      0.69      1027\n",
      "        spam       0.00      0.00      0.00       393\n",
      "\n",
      "    accuracy                           0.67      2970\n",
      "   macro avg       0.44      0.51      0.48      2970\n",
      "weighted avg       0.58      0.67      0.62      2970\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.94      0.74      1550\n",
      "           1       0.80      0.45      0.58      1027\n",
      "        spam       0.00      0.00      0.00       393\n",
      "\n",
      "    accuracy                           0.65      2970\n",
      "   macro avg       0.47      0.46      0.44      2970\n",
      "weighted avg       0.59      0.65      0.58      2970\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      1.00      0.71      1550\n",
      "           1       1.00      0.14      0.24      1027\n",
      "        spam       0.00      0.00      0.00       392\n",
      "\n",
      "    accuracy                           0.57      2969\n",
      "   macro avg       0.52      0.38      0.32      2969\n",
      "weighted avg       0.63      0.57      0.45      2969\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.99      0.70      1549\n",
      "           1       0.88      0.08      0.15      1027\n",
      "        spam       0.00      0.00      0.00       393\n",
      "\n",
      "    accuracy                           0.55      2969\n",
      "   macro avg       0.47      0.36      0.28      2969\n",
      "weighted avg       0.59      0.55      0.41      2969\n",
      "\n",
      "MultinomialNB  1 - gram with stopwords :  0.6180173804963296\n"
     ]
    }
   ],
   "source": [
    "acc_list = []\n",
    "for i in range(1, 2):\n",
    "    for exp in [True, False]:\n",
    "        X = data['text'].values.astype('U')\n",
    "        y = data[\"label\"].values.astype('U')\n",
    "        X = bag_word(X, stop_word=exp, n_gram=(i, i))\n",
    "        clfrNB = MultinomialNB()\n",
    "        scores = cross_val_score(clfrNB, X, y,  cv=10,\n",
    "                                scoring = make_scorer(classification_report_with_accuracy_score))\n",
    "        acc = scores.mean()\n",
    "        acc_list.append(acc)\n",
    "        if exp:\n",
    "            print(\"MultinomialNB \", i, \"- gram without stopwords : \", acc) \n",
    "        else:\n",
    "            print(\"MultinomialNB \", i, \"- gram with stopwords : \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ei6F-UxMa7-T"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "machine_shape": "hm",
   "name": "NaiveBayes_dataset4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
